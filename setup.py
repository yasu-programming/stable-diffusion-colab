#!/usr/bin/env python3
"""
Google Colabç”¨ Stable Diffusion ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä½¿ç”¨æ–¹æ³•: python setup.py
"""

import subprocess
import sys
import os
import torch
from pathlib import Path

def run_command(command, description=""):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    if description:
        print(f"ğŸ”„ {description}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                              capture_output=True, text=True)
        if result.stdout:
            print(f"âœ… {description} - å®Œäº†")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {description}")
        print(f"ã‚³ãƒãƒ³ãƒ‰: {command}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}")
        return False

def check_gpu():
    """GPUåˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” GPUç¢ºèªä¸­...")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ… GPUåˆ©ç”¨å¯èƒ½: {gpu_name}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        return True
    else:
        print("âŒ GPUåˆ©ç”¨ä¸å¯ - CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ï¼ˆéå¸¸ã«é…ã„ï¼‰")
        return False

def install_dependencies():
    """å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    print("ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    
    # å•é¡Œã®ã‚ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’å®Œå…¨å‰Šé™¤
    print("ğŸ—‘ï¸ æ—¢å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å‰Šé™¤ä¸­...")
    packages_to_remove = ["torch", "torchvision", "torchaudio", "numpy", "diffusers", "transformers", "huggingface_hub", "xformers"]
    for package in packages_to_remove:
        run_command(f"pip uninstall -y {package}", f"{package} å‰Šé™¤")
    
    # ç¾ä»£çš„ã§ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    print("ğŸ”§ NumPy 1.26.4 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«...")
    run_command("pip install numpy==1.26.4", "NumPy 1.26.4å›ºå®š")
    
    # PyTorch 2.2.2ï¼ˆNumPy 1.26.4ã¨äº’æ›ã€ç¾ä»£çš„ï¼‰
    torch_install = run_command(
        "pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu118",
        "PyTorch 2.2.2 ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
    )
    
    if not torch_install:
        print("âš ï¸ CUDAç‰ˆPyTorchã«å¤±æ•—ã€CPUç‰ˆã‚’è©¦è¡Œä¸­...")
        run_command("pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2", "PyTorch 2.2.2 (CPUç‰ˆ)")
    
    # Hugging Face Hub ç¾ä»£ç‰ˆ
    run_command("pip install huggingface_hub==0.24.6", "Hugging Face Hub 0.24.6")
    
    # ãã®ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆç¾ä»£çš„ã§ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    packages = [
        "diffusers==0.30.0",  # æœ€æ–°ç‰ˆï¼ˆNumPy 1.26.4ã¨äº’æ›ï¼‰
        "transformers==4.44.0",  # æœ€æ–°ç‰ˆ
        "accelerate==0.34.0",  # æœ€æ–°ç‰ˆ
        "safetensors==0.4.4",   # æœ€æ–°ç‰ˆ
        "pillow>=9.0.0",
        "matplotlib>=3.5.0",
        "ipywidgets>=8.0.0"
    ]
    
    for package in packages:
        success = run_command(f"pip install {package}", f"{package} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        if not success:
            print(f"âš ï¸  {package} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™")
    
    # xformers ç¾ä»£ç‰ˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    print("ğŸ”§ xformers ç¾ä»£ç‰ˆ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    xformers_success = run_command("pip install xformers==0.0.27", "xformers 0.0.27")
    if not xformers_success:
        print("âš ï¸ xformersã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•— - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ãªã—ã§ç¶šè¡Œ")

def setup_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    print("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šä¸­...")
    
    directories = [
        "generated_images",
        "models_cache", 
        "temp"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… {directory}/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ")

def download_models():
    """æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰"""
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    try:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        print("ğŸ” ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèªä¸­...")
        import torch
        print(f"âœ… PyTorch {torch.__version__}")
        
        from diffusers import StableDiffusionPipeline
        print("âœ… Diffusers ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # SD 1.5ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¥ Stable Diffusion v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            cache_dir="./models_cache",
            safety_checker=None,
            requires_safety_checker=False
        )
        print("âœ… SD v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        # ç¾ä»£çš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
        if torch.cuda.is_available():
            try:
                pipe.enable_memory_efficient_attention()
                print("âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)[:50]}")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del pipe
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("âœ… GPUãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢å®Œäº†")
        
        return True
    except ImportError as e:
        print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è©¦ã—ã¦ãã ã•ã„: pip install --upgrade diffusers transformers")
        return False
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ æ‰‹å‹•ã§ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        return False

def create_quick_start():
    """ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    print("ğŸ“ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    
    quick_start_code = '''
# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import matplotlib.pyplot as plt

def generate_image(prompt, negative_prompt="", width=512, height=512):
    """ç”»åƒç”Ÿæˆé–¢æ•°"""
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        cache_dir="./models_cache"
    )
    
    if torch.cuda.is_available():
        pipe = pipe.to("cuda")
        
        # ç¾ä»£çš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        try:
            pipe.enable_memory_efficient_attention()
            print("âœ… ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ– ON")
        except Exception as e:
            print(f"âš ï¸ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚¹ã‚­ãƒƒãƒ—: {str(e)[:50]}")
        
        try:
            pipe.enable_model_cpu_offload()
            print("âœ… CPU Offload ON")
        except Exception as e:
            print(f"âš ï¸ CPU Offloadã‚¹ã‚­ãƒƒãƒ—: {str(e)[:50]}")
    
    # ç”»åƒç”Ÿæˆ
    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=20,
        guidance_scale=7.5
    ).images[0]
    
    return image

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # YouTubeã‚µãƒ ãƒã‚¤ãƒ«ä¾‹
    prompt = "modern tech office, programmer, clean design, professional lighting"
    negative_prompt = "blurry, low quality, messy"
    
    image = generate_image(prompt, negative_prompt, width=896, height=512)
    
    # è¡¨ç¤ºã¨ä¿å­˜
    plt.figure(figsize=(12, 6))
    plt.imshow(image)
    plt.axis("off")
    plt.title(f"Generated: {prompt[:50]}...")
    plt.show()
    
    image.save("generated_images/sample_thumbnail.png")
    print("ç”»åƒã‚’ generated_images/sample_thumbnail.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
'''
    
    with open("quick_start.py", "w", encoding="utf-8") as f:
        f.write(quick_start_code)
    
    print("âœ… quick_start.py ä½œæˆå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Stable Diffusion Colab ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
    print("=" * 50)
    
    # GPUç¢ºèª
    gpu_available = check_gpu()
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    install_dependencies()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    setup_directories()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if gpu_available:
        download_models()
    else:
        print("âš ï¸  GPUåˆ©ç”¨ä¸å¯ã®ãŸã‚ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    create_quick_start()
    
    print("=" * 50)
    print("ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    print("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. python quick_start.py ã§ç”»åƒç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("   2. generated_images/ ãƒ•ã‚©ãƒ«ãƒ€ã§ç”Ÿæˆç”»åƒã‚’ç¢ºèª")
    print("   3. docs/ ãƒ•ã‚©ãƒ«ãƒ€ã®ä½¿ç”¨ä¾‹ã‚’å‚è€ƒã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º")
    
    if gpu_available:
        print("âš¡ GPUåˆ©ç”¨å¯èƒ½ - é«˜é€Ÿç”Ÿæˆã§ãã¾ã™")
    else:
        print("ğŸŒ CPUåˆ©ç”¨ - ç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")

if __name__ == "__main__":
    main()