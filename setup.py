#!/usr/bin/env python3
"""
Google Colabç”¨ Stable Diffusion ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä½¿ç”¨æ–¹æ³•: python setup.py
"""

import subprocess
import sys
import os
import torch
from pathlib import Path

def run_command(command, description=""):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    if description:
        print(f"ğŸ”„ {description}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                              capture_output=True, text=True)
        if result.stdout:
            print(f"âœ… {description} - å®Œäº†")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {description}")
        print(f"ã‚³ãƒãƒ³ãƒ‰: {command}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}")
        return False

def check_gpu():
    """GPUåˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” GPUç¢ºèªä¸­...")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ… GPUåˆ©ç”¨å¯èƒ½: {gpu_name}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        return True
    else:
        print("âŒ GPUåˆ©ç”¨ä¸å¯ - CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ï¼ˆéå¸¸ã«é…ã„ï¼‰")
        return False

def install_dependencies():
    """å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    print("ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    
    # PyTorchã‚’å…ˆã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šï¼‰
    torch_install = run_command(
        "pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118",
        "PyTorch ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
    )
    
    if not torch_install:
        print("âš ï¸ PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰ˆã‚’è©¦è¡Œä¸­...")
        run_command("pip install torch torchvision torchaudio", "PyTorch (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰ˆ)")
    
    # Hugging Face Hub ã‚’å…ˆã«ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
    run_command("pip install --upgrade huggingface_hub", "Hugging Face Hub ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰")
    
    # ãã®ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§è€ƒæ…®ï¼‰
    packages = [
        "diffusers==0.25.1",  # å®‰å®šç‰ˆ
        "transformers==4.36.0",  # äº’æ›æ€§ç¢ºèªæ¸ˆã¿
        "accelerate==0.25.0",
        "safetensors==0.4.0",
        "huggingface_hub>=0.20.0",  # æ˜ç¤ºçš„ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®š
        "pillow>=9.0.0",
        "numpy>=1.21.0",
        "matplotlib>=3.5.0",
        "ipywidgets>=8.0.0"
    ]
    
    for package in packages:
        success = run_command(f"pip install {package}", f"{package} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        if not success:
            print(f"âš ï¸  {package} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™")
    
    # xformersã¯æœ€å¾Œã«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    print("ğŸ”§ xformers ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰...")
    run_command("pip install xformers --no-deps", "xformers ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")

def setup_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    print("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šä¸­...")
    
    directories = [
        "generated_images",
        "models_cache", 
        "temp"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… {directory}/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ")

def download_models():
    """æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰"""
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    try:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        print("ğŸ” ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèªä¸­...")
        import torch
        print(f"âœ… PyTorch {torch.__version__}")
        
        from diffusers import StableDiffusionPipeline
        print("âœ… Diffusers ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
        
        # SD 1.5ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¥ Stable Diffusion v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            cache_dir="./models_cache",
            safety_checker=None,
            requires_safety_checker=False
        )
        print("âœ… SD v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del pipe
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return True
    except ImportError as e:
        print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è©¦ã—ã¦ãã ã•ã„: pip install --upgrade diffusers transformers")
        return False
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ æ‰‹å‹•ã§ãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        return False

def create_quick_start():
    """ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    print("ğŸ“ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    
    quick_start_code = '''
# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import matplotlib.pyplot as plt

def generate_image(prompt, negative_prompt="", width=512, height=512):
    """ç”»åƒç”Ÿæˆé–¢æ•°"""
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        cache_dir="./models_cache"
    )
    
    if torch.cuda.is_available():
        pipe = pipe.to("cuda")
        pipe.enable_memory_efficient_attention()
        pipe.enable_model_cpu_offload()
    
    # ç”»åƒç”Ÿæˆ
    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=20,
        guidance_scale=7.5
    ).images[0]
    
    return image

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # YouTubeã‚µãƒ ãƒã‚¤ãƒ«ä¾‹
    prompt = "modern tech office, programmer, clean design, professional lighting"
    negative_prompt = "blurry, low quality, messy"
    
    image = generate_image(prompt, negative_prompt, width=896, height=512)
    
    # è¡¨ç¤ºã¨ä¿å­˜
    plt.figure(figsize=(12, 6))
    plt.imshow(image)
    plt.axis("off")
    plt.title(f"Generated: {prompt[:50]}...")
    plt.show()
    
    image.save("generated_images/sample_thumbnail.png")
    print("ç”»åƒã‚’ generated_images/sample_thumbnail.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
'''
    
    with open("quick_start.py", "w", encoding="utf-8") as f:
        f.write(quick_start_code)
    
    print("âœ… quick_start.py ä½œæˆå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Stable Diffusion Colab ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
    print("=" * 50)
    
    # GPUç¢ºèª
    gpu_available = check_gpu()
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    install_dependencies()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    setup_directories()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if gpu_available:
        download_models()
    else:
        print("âš ï¸  GPUåˆ©ç”¨ä¸å¯ã®ãŸã‚ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    create_quick_start()
    
    print("=" * 50)
    print("ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    print("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. python quick_start.py ã§ç”»åƒç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("   2. generated_images/ ãƒ•ã‚©ãƒ«ãƒ€ã§ç”Ÿæˆç”»åƒã‚’ç¢ºèª")
    print("   3. docs/ ãƒ•ã‚©ãƒ«ãƒ€ã®ä½¿ç”¨ä¾‹ã‚’å‚è€ƒã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º")
    
    if gpu_available:
        print("âš¡ GPUåˆ©ç”¨å¯èƒ½ - é«˜é€Ÿç”Ÿæˆã§ãã¾ã™")
    else:
        print("ğŸŒ CPUåˆ©ç”¨ - ç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")

if __name__ == "__main__":
    main()