#!/usr/bin/env python3
"""
Google Colabç”¨ Stable Diffusion ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä½¿ç”¨æ–¹æ³•: python setup.py
"""

import subprocess
import sys
import os
import torch
from pathlib import Path

def run_command(command, description=""):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¡¨ç¤º"""
    if description:
        print(f"ğŸ”„ {description}")
    
    try:
        result = subprocess.run(command, shell=True, check=True, 
                              capture_output=True, text=True)
        if result.stdout:
            print(f"âœ… {description} - å®Œäº†")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {description}")
        print(f"ã‚³ãƒãƒ³ãƒ‰: {command}")
        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e.stderr}")
        return False

def check_gpu():
    """GPUåˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” GPUç¢ºèªä¸­...")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        print(f"âœ… GPUåˆ©ç”¨å¯èƒ½: {gpu_name}")
        print(f"ğŸ’¾ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        return True
    else:
        print("âŒ GPUåˆ©ç”¨ä¸å¯ - CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ï¼ˆéå¸¸ã«é…ã„ï¼‰")
        return False

def install_dependencies():
    """å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    print("ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
    
    # åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    packages = [
        "diffusers[torch]",
        "transformers", 
        "accelerate",
        "safetensors",
        "xformers",  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        "pillow",
        "numpy",
        "matplotlib",
        "ipywidgets"  # Colabç”¨UI
    ]
    
    for package in packages:
        success = run_command(f"pip install {package}", f"{package} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        if not success:
            print(f"âš ï¸  {package} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸãŒç¶šè¡Œã—ã¾ã™")

def setup_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    print("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šä¸­...")
    
    directories = [
        "generated_images",
        "models_cache", 
        "temp"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"âœ… {directory}/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ")

def download_models():
    """æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰"""
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    try:
        from diffusers import StableDiffusionPipeline
        import torch
        
        # SD 1.5ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        print("ğŸ“¥ Stable Diffusion v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch.float16,
            cache_dir="./models_cache"
        )
        print("âœ… SD v1.5 ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        
        return True
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def create_quick_start():
    """ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ"""
    print("ğŸ“ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­...")
    
    quick_start_code = '''
# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import matplotlib.pyplot as plt

def generate_image(prompt, negative_prompt="", width=512, height=512):
    """ç”»åƒç”Ÿæˆé–¢æ•°"""
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        cache_dir="./models_cache"
    )
    
    if torch.cuda.is_available():
        pipe = pipe.to("cuda")
        pipe.enable_memory_efficient_attention()
        pipe.enable_model_cpu_offload()
    
    # ç”»åƒç”Ÿæˆ
    image = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        width=width,
        height=height,
        num_inference_steps=20,
        guidance_scale=7.5
    ).images[0]
    
    return image

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # YouTubeã‚µãƒ ãƒã‚¤ãƒ«ä¾‹
    prompt = "modern tech office, programmer, clean design, professional lighting"
    negative_prompt = "blurry, low quality, messy"
    
    image = generate_image(prompt, negative_prompt, width=896, height=512)
    
    # è¡¨ç¤ºã¨ä¿å­˜
    plt.figure(figsize=(12, 6))
    plt.imshow(image)
    plt.axis("off")
    plt.title(f"Generated: {prompt[:50]}...")
    plt.show()
    
    image.save("generated_images/sample_thumbnail.png")
    print("ç”»åƒã‚’ generated_images/sample_thumbnail.png ã«ä¿å­˜ã—ã¾ã—ãŸ")
'''
    
    with open("quick_start.py", "w", encoding="utf-8") as f:
        f.write(quick_start_code)
    
    print("âœ… quick_start.py ä½œæˆå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ Stable Diffusion Colab ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
    print("=" * 50)
    
    # GPUç¢ºèª
    gpu_available = check_gpu()
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    install_dependencies()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
    setup_directories()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if gpu_available:
        download_models()
    else:
        print("âš ï¸  GPUåˆ©ç”¨ä¸å¯ã®ãŸã‚ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    create_quick_start()
    
    print("=" * 50)
    print("ğŸ‰ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    print("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. python quick_start.py ã§ç”»åƒç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("   2. generated_images/ ãƒ•ã‚©ãƒ«ãƒ€ã§ç”Ÿæˆç”»åƒã‚’ç¢ºèª")
    print("   3. docs/ ãƒ•ã‚©ãƒ«ãƒ€ã®ä½¿ç”¨ä¾‹ã‚’å‚è€ƒã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º")
    
    if gpu_available:
        print("âš¡ GPUåˆ©ç”¨å¯èƒ½ - é«˜é€Ÿç”Ÿæˆã§ãã¾ã™")
    else:
        print("ğŸŒ CPUåˆ©ç”¨ - ç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")

if __name__ == "__main__":
    main()