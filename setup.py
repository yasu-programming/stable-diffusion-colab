#!/usr/bin/env python3
"""
SDXL Base 1.0 è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Google Colabç’°å¢ƒã§ã®Stable Diffusion XLç’°å¢ƒæ§‹ç¯‰

ä½¿ç”¨æ–¹æ³•:
    python setup.py

æ©Ÿèƒ½:
- å…¬å¼æ¨å¥¨ä¾å­˜é–¢ä¿‚ã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- SDXL Base 1.0ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
- Colabç„¡æ–™ç‰ˆç”¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–è¨­å®š
- å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import subprocess
import time
import gc
from pathlib import Path

def print_header():
    """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    print("=" * 60)
    print("ğŸš€ SDXL Base 1.0 è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— for Google Colab")
    print("=" * 60)
    print("ğŸ“‹ è¨­å®šå†…å®¹:")
    print("   - Stable Diffusion XL Base 1.0")
    print("   - Google Colab ç„¡æ–™ç‰ˆå¯¾å¿œ")
    print("   - å•†ç”¨åˆ©ç”¨å¯èƒ½ (CreativeML Open RAIL++-M)")
    print("   - YouTubeãƒ»Noteç”¨ç”»åƒç”Ÿæˆç‰¹åŒ–")
    print("=" * 60)

def check_environment():
    """ç’°å¢ƒãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” ç’°å¢ƒãƒã‚§ãƒƒã‚¯...")
    
    # Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
    python_version = sys.version_info
    print(f"   Python: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version < (3, 8):
        print("âŒ Python 3.8ä»¥ä¸ŠãŒå¿…è¦ã§ã™")
        return False
    
    # GPUç¢ºèª
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        print(f"   CUDA: {'åˆ©ç”¨å¯èƒ½' if cuda_available else 'åˆ©ç”¨ä¸å¯'}")
        
        if cuda_available:
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"   GPU: {gpu_name}")
            print(f"   VRAM: {gpu_memory:.1f}GB")
            
            if gpu_memory < 8:
                print("âš ï¸  VRAM 8GBæœªæº€ï¼šãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ã‚’å¼·åŒ–ã—ã¾ã™")
        else:
            print("âŒ CUDAå¯¾å¿œGPUãŒå¿…è¦ã§ã™")
            return False
            
    except ImportError:
        print("   PyTorch: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¾Œã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰")
    
    print("âœ… ç’°å¢ƒãƒã‚§ãƒƒã‚¯å®Œäº†")
    return True

def install_dependencies():
    """å…¬å¼æ¨å¥¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    print("\nğŸ“¦ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«...")
    
    # åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆï¼ˆå…¬å¼æ¨å¥¨é †ï¼‰
    packages = [
        # Core packages (å…¬å¼æ¨å¥¨)
        ("diffusers>=0.19.0", "Diffusers (SDXLå¯¾å¿œç‰ˆ)"),
        ("transformers", "Transformers"),
        ("safetensors", "SafeTensors"),
        ("accelerate", "Accelerate"),
        ("invisible_watermark", "Invisible Watermark"),
        
        # PyTorch (CUDAå¯¾å¿œ)
        ("torch torchvision --index-url https://download.pytorch.org/whl/cu118", "PyTorch (CUDA 11.8)"),
        
        # ç”»åƒå‡¦ç†ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        ("pillow", "Pillow"),
        ("opencv-python", "OpenCV"),
        ("tqdm", "Progress Bar"),
        ("matplotlib", "Matplotlib"),
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šé«˜é€ŸåŒ–
        ("xformers", "xFormers (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)"),
    ]
    
    successful_installs = []
    failed_installs = []
    
    for package_spec, description in packages:
        print(f"\n   ğŸ“¥ {description} ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
        
        try:
            # xformersã¯å¤±æ•—ã—ã¦ã‚‚ã‚¹ã‚­ãƒƒãƒ—
            if "xformers" in package_spec:
                try:
                    result = subprocess.run(
                        [sys.executable, "-m", "pip", "install"] + package_spec.split(),
                        capture_output=True, text=True, timeout=300
                    )
                except subprocess.TimeoutExpired:
                    print(f"   â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {description} (ã‚¹ã‚­ãƒƒãƒ—)")
                    continue
            else:
                result = subprocess.run(
                    [sys.executable, "-m", "pip", "install"] + package_spec.split(),
                    capture_output=True, text=True, timeout=600
                )
            
            if result.returncode == 0:
                print(f"   âœ… {description} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æˆåŠŸ")
                successful_installs.append(description)
            else:
                print(f"   âŒ {description} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—")
                if "xformers" not in package_spec:  # xformersä»¥å¤–ã¯é‡è¦
                    print(f"      ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                failed_installs.append(description)
                
        except Exception as e:
            print(f"   âŒ {description} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—: {str(e)[:100]}")
            failed_installs.append(description)
    
    print(f"\nğŸ“Š ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«çµæœ:")
    print(f"   âœ… æˆåŠŸ: {len(successful_installs)}")
    print(f"   âŒ å¤±æ•—: {len(failed_installs)}")
    
    if failed_installs:
        print(f"   å¤±æ•—ã—ãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {', '.join(failed_installs)}")
    
    return len(failed_installs) == 0 or all("xformers" in pkg for pkg in failed_installs)

def setup_directories():
    """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ"""
    print("\nğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆä¸­...")
    
    directories = [
        "generated_images",
        "models_cache", 
        "logs",
        "temp"
    ]
    
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"   ğŸ“‚ {directory}/")
    
    print("âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆå®Œäº†")

def setup_sdxl_pipeline():
    """SDXL ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åˆæœŸåŒ–"""
    print("\nğŸ¨ SDXL ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’åˆæœŸåŒ–ä¸­...")
    
    try:
        # Import all required libraries
        import torch
        from diffusers import DiffusionPipeline
        print("   ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿å®Œäº†")
        
        # Clear memory
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        gc.collect()
        
        print("   ğŸ”„ SDXL Base 1.0 ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        print("      (åˆå›ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")
        
        # Setup pipeline with official recommendations
        pipe = DiffusionPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch.float16,      # Memory efficiency
            use_safetensors=True,           # Security
            variant="fp16"                  # Lightweight model
        )
        print("   âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # Apply Colab optimizations
        print("   âš¡ Google Colab æœ€é©åŒ–ã‚’é©ç”¨ä¸­...")
        
        # Essential optimizations for Colab free tier
        pipe.enable_model_cpu_offload()   # Official recommendation for low VRAM
        pipe.vae.enable_tiling()          # For high resolution generation
        
        # Optional optimizations (fail gracefully)
        try:
            pipe.enable_xformers_memory_efficient_attention()
            print("   âœ… xFormers ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–: æœ‰åŠ¹")
        except:
            print("   âš ï¸  xFormers ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–: ç„¡åŠ¹ (ã‚¹ã‚­ãƒƒãƒ—)")
        
        try:
            # torch.compile for 20-30% speedup (if supported)
            pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
            print("   âœ… torch.compile é«˜é€ŸåŒ–: æœ‰åŠ¹")
        except:
            print("   âš ï¸  torch.compile é«˜é€ŸåŒ–: ç„¡åŠ¹ (ã‚µãƒãƒ¼ãƒˆå¤–)")
        
        print("âœ… SDXL ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æº–å‚™å®Œäº†")
        return pipe
        
    except Exception as e:
        print(f"âŒ SDXL ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å¤±æ•—: {e}")
        return None

def run_test_generation(pipe):
    """ãƒ†ã‚¹ãƒˆç”»åƒç”Ÿæˆ"""
    print("\nğŸ§ª ãƒ†ã‚¹ãƒˆç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    try:
        # Simple test prompt
        test_prompt = "A beautiful landscape with mountains and a lake, digital art, high quality"
        
        print(f"   ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {test_prompt}")
        print("   â±ï¸  ç”Ÿæˆä¸­... (1-2åˆ†ãŠå¾…ã¡ãã ã•ã„)")
        
        start_time = time.time()
        
        # Generate test image
        images = pipe(
            prompt=test_prompt,
            height=1024,
            width=1024,
            num_inference_steps=20,  # Fast test
            guidance_scale=7.5,
            num_images_per_prompt=1
        ).images
        
        generation_time = time.time() - start_time
        
        # Save test image
        test_image = images[0]
        test_path = "generated_images/setup_test.png"
        test_image.save(test_path)
        
        print(f"   âœ… ãƒ†ã‚¹ãƒˆç”»åƒç”ŸæˆæˆåŠŸ")
        print(f"   ğŸ“¸ ä¿å­˜å…ˆ: {test_path}")
        print(f"   â±ï¸  ç”Ÿæˆæ™‚é–“: {generation_time:.2f}ç§’")
        print(f"   ğŸ“ è§£åƒåº¦: {test_image.size}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ãƒ†ã‚¹ãƒˆç”»åƒç”Ÿæˆå¤±æ•—: {e}")
        return False

def cleanup_and_optimize():
    """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨æœ€é©åŒ–"""
    print("\nğŸ§¹ ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
            # Memory status
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            print(f"   ğŸ“Š GPU ãƒ¡ãƒ¢ãƒª - ä½¿ç”¨ä¸­: {allocated:.2f}GB, äºˆç´„æ¸ˆã¿: {reserved:.2f}GB")
        
        gc.collect()
        print("   âœ… ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        
    except Exception as e:
        print(f"   âš ï¸  ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—è­¦å‘Š: {e}")

def save_setup_info():
    """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æƒ…å ±ã®ä¿å­˜"""
    print("\nğŸ’¾ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æƒ…å ±ã‚’ä¿å­˜ä¸­...")
    
    try:
        import torch
        import diffusers
        import transformers
        from datetime import datetime
        
        setup_info = {
            "setup_date": datetime.now().isoformat(),
            "python_version": f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
            "torch_version": torch.__version__,
            "diffusers_version": diffusers.__version__,
            "transformers_version": transformers.__version__,
            "cuda_available": torch.cuda.is_available(),
        }
        
        if torch.cuda.is_available():
            setup_info.update({
                "gpu_name": torch.cuda.get_device_name(0),
                "gpu_memory_gb": torch.cuda.get_device_properties(0).total_memory / 1e9,
                "cuda_version": torch.version.cuda,
            })
        
        # Save to file
        import json
        with open("setup_info.json", "w", encoding="utf-8") as f:
            json.dump(setup_info, f, indent=2, ensure_ascii=False)
        
        print("   âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æƒ…å ±ä¿å­˜å®Œäº†: setup_info.json")
        
    except Exception as e:
        print(f"   âš ï¸  æƒ…å ±ä¿å­˜è­¦å‘Š: {e}")

def print_completion_message():
    """å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    print("\n" + "=" * 60)
    print("ğŸ‰ SDXL ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    print("=" * 60)
    print("ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. python sdxl_test.py      # ã‚ˆã‚Šè©³ç´°ãªãƒ†ã‚¹ãƒˆ")
    print("   2. ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’ç¢ºèª      # generated_images/setup_test.png")
    print("   3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§        # docs/README.md")
    print("\nğŸ“š ä¸»è¦ã‚³ãƒãƒ³ãƒ‰:")
    print("   - YouTube ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆ")
    print("   - Note è¨˜äº‹ç”¨ç”»åƒç”Ÿæˆ") 
    print("   - ã‚¢ã‚¤ã‚³ãƒ³ãƒ»ãƒ­ã‚´ä½œæˆ")
    print("\nğŸ”§ å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆ:")
    print("   python scripts/sdxl_fix.py  # ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ")
    print("=" * 60)
    print("âœ¨ é«˜å“è³ªãªç”»åƒç”Ÿæˆã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ï¼")
    print("=" * 60)

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    start_time = time.time()
    
    try:
        # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
        print_header()
        
        if not check_environment():
            print("âŒ ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        if not install_dependencies():
            print("âŒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        setup_directories()
        
        pipe = setup_sdxl_pipeline()
        if pipe is None:
            print("âŒ SDXL ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        if not run_test_generation(pipe):
            print("âŒ ãƒ†ã‚¹ãƒˆç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        cleanup_and_optimize()
        save_setup_info()
        
        total_time = time.time() - start_time
        print(f"\nâ±ï¸  ç·ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ™‚é–“: {total_time/60:.1f}åˆ†")
        
        print_completion_message()
        return True
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return False
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)