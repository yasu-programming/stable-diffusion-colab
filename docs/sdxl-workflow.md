# SDXL ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰

Stable Diffusion XL Base 1.0ã‚’ä½¿ç”¨ã—ãŸYouTubeãƒ»Noteç”¨ç”»åƒç”Ÿæˆã®å®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã§ã™ã€‚

## ğŸ¯ SDXL ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ¦‚è¦

### åŸºæœ¬ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
1. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ** â†’ ç›®çš„ã«å¿œã˜ãŸè©³ç´°ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
2. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´** â†’ ç”¨é€”åˆ¥ã®æœ€é©è¨­å®š
3. **åˆæœŸç”Ÿæˆ** â†’ ãƒ™ãƒ¼ã‚¹ç”»åƒã®ç”Ÿæˆ
4. **å“è³ªè©•ä¾¡** â†’ çµæœã®ç¢ºèªã¨æ”¹å–„ç‚¹ç‰¹å®š
5. **ãƒªãƒ•ã‚¡ã‚¤ãƒ³** â†’ å¿…è¦ã«å¿œã˜ãŸå†ç”Ÿæˆãƒ»èª¿æ•´
6. **å¾Œå‡¦ç†** â†’ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãƒ»ã‚µã‚¤ã‚ºèª¿æ•´

### SDXLç‰¹æœ‰ã®ç‰¹å¾´
- **é«˜è§£åƒåº¦æ¨™æº–**: 1024Ã—1024ãŒåŸºæœ¬
- **è©³ç´°ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç†è§£**: è¤‡é›‘ãªæŒ‡ç¤ºã«ã‚‚å¯¾å¿œ
- **å®‰å®šã—ãŸå“è³ª**: ä¸€è²«æ€§ã®ã‚ã‚‹é«˜å“è³ªå‡ºåŠ›
- **æŸ”è»Ÿãªã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”**: æ§˜ã€…ãªæ¯”ç‡ã«å¯¾å¿œ

## ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆæˆ¦ç•¥

### SDXLã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ 

```python
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
template = """
{main_subject}, {style_description}, {technical_specs}, {quality_modifiers}
"""

# ä¾‹ï¼šYouTubeã‚µãƒ ãƒã‚¤ãƒ«ç”¨
youtube_prompt = """
A vibrant gaming setup with RGB lighting, modern gaming chair and multiple monitors, 
cyberpunk style, neon colors, high contrast, professional photography, 
ultra detailed, 8K resolution, trending on artstation
"""

# ä¾‹ï¼šNoteè¨˜äº‹ç”¨
note_prompt = """
A minimalist workspace with laptop, coffee cup and notebook on wooden desk, 
natural lighting from window, soft shadows, clean composition, 
professional stock photo style, high quality, commercial photography
"""
```

### åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¦ç´ 

#### 1. ä¸»è¦è¢«å†™ä½“ã®æ˜ç¢ºåŒ–
```python
subjects = [
    "A professional businessman",
    "Modern smartphone on desk", 
    "Cozy living room interior",
    "Abstract geometric pattern"
]
```

#### 2. ã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®š
```python
styles = [
    "professional photography",
    "digital art illustration", 
    "minimalist design",
    "vintage aesthetic",
    "cyberpunk style"
]
```

#### 3. å“è³ªå‘ä¸Šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
```python
quality_terms = [
    "ultra detailed", "8K resolution", "high quality",
    "professional lighting", "sharp focus", "vivid colors",
    "trending on artstation", "award winning"
]
```

## âš™ï¸ ç”¨é€”åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š

### YouTube ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆ

```python
def generate_youtube_thumbnail(prompt, pipe):
    """YouTube ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ç”»åƒç”Ÿæˆ"""
    config = {
        "prompt": prompt,
        "negative_prompt": "blurry, low quality, distorted, watermark, text",
        "height": 576,           # 16:9 æ¯”ç‡ï¼ˆ1024x576ï¼‰
        "width": 1024,
        "num_inference_steps": 25,
        "guidance_scale": 8.0,   # å¼·ã‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
        "num_images_per_prompt": 4,  # è¤‡æ•°ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    }
    
    images = pipe(**config).images
    return images

# ä½¿ç”¨ä¾‹
youtube_prompt = """
Excited gamer with headphones playing video game, colorful RGB background, 
dynamic action scene, vibrant colors, professional gaming photography, 
high energy, dramatic lighting, ultra detailed
"""

thumbnail_images = generate_youtube_thumbnail(youtube_prompt, pipe)
```

### Noteãƒ»ãƒ–ãƒ­ã‚°è¨˜äº‹ç”¨ç”»åƒ

```python
def generate_blog_image(prompt, pipe):
    """ãƒ–ãƒ­ã‚°è¨˜äº‹ç”¨ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒç”Ÿæˆ"""
    config = {
        "prompt": prompt,
        "negative_prompt": "cluttered, messy, low quality, amateur",
        "height": 536,           # 1.91:1 æ¯”ç‡ï¼ˆ1024x536ï¼‰
        "width": 1024,
        "num_inference_steps": 30,
        "guidance_scale": 7.5,
        "num_images_per_prompt": 2,
    }
    
    images = pipe(**config).images
    return images

# ä½¿ç”¨ä¾‹
blog_prompt = """
Clean modern office workspace with laptop, notebook and coffee, 
natural lighting, minimalist design, productivity concept, 
professional stock photography, soft colors, high quality
"""

blog_images = generate_blog_image(blog_prompt, pipe)
```

### ã‚¢ã‚¤ã‚³ãƒ³ãƒ»ãƒ­ã‚´ç”¨ç”»åƒ

```python
def generate_icon(prompt, pipe):
    """ã‚¢ã‚¤ã‚³ãƒ³ãƒ»ãƒ­ã‚´ç”¨ç”»åƒç”Ÿæˆ"""
    config = {
        "prompt": prompt,
        "negative_prompt": "complex, detailed background, realistic, photographic",
        "height": 1024,          # æ­£æ–¹å½¢
        "width": 1024,
        "num_inference_steps": 35,
        "guidance_scale": 9.0,   # æœ€å¼·ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
        "num_images_per_prompt": 6,  # å¤šæ•°ç”Ÿæˆã§é¸æŠ
    }
    
    images = pipe(**config).images
    return images

# ä½¿ç”¨ä¾‹
icon_prompt = """
Simple geometric logo design, abstract symbol, clean lines, 
modern minimalist style, single color on white background, 
vector art style, professional branding, scalable design
"""

icon_images = generate_icon(icon_prompt, pipe)
```

## ğŸ”„ ãƒãƒƒãƒå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### åŠ¹ç‡çš„ãªå¤§é‡ç”Ÿæˆ

```python
def batch_generate_images(prompts, pipe, output_dir="generated_images"):
    """è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†"""
    import os
    from datetime import datetime
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    batch_dir = os.path.join(output_dir, f"batch_{timestamp}")
    os.makedirs(batch_dir, exist_ok=True)
    
    results = []
    
    for i, prompt_config in enumerate(prompts):
        print(f"Processing {i+1}/{len(prompts)}: {prompt_config['name']}")
        
        try:
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢
            torch.cuda.empty_cache()
            
            # ç”»åƒç”Ÿæˆ
            images = pipe(**prompt_config['config']).images
            
            # ä¿å­˜
            for j, image in enumerate(images):
                filename = f"{prompt_config['name']}_{j+1}.png"
                filepath = os.path.join(batch_dir, filename)
                image.save(filepath)
                results.append({
                    'prompt': prompt_config['name'],
                    'file': filepath,
                    'config': prompt_config['config']
                })
            
            print(f"âœ… Saved {len(images)} images")
            
        except Exception as e:
            print(f"âŒ Error processing {prompt_config['name']}: {e}")
            continue
    
    return results, batch_dir

# ä½¿ç”¨ä¾‹
batch_prompts = [
    {
        "name": "tech_thumbnail_1",
        "config": {
            "prompt": "Modern laptop with coding screen, programmer workspace, tech setup",
            "height": 576, "width": 1024,
            "num_inference_steps": 25,
            "num_images_per_prompt": 2
        }
    },
    {
        "name": "business_blog_1", 
        "config": {
            "prompt": "Professional meeting room, business discussion, modern office",
            "height": 536, "width": 1024,
            "num_inference_steps": 30,
            "num_images_per_prompt": 2
        }
    }
]

results, output_dir = batch_generate_images(batch_prompts, pipe)
```

## ğŸ¨ ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–æŠ€æ³•

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ®µéšçš„æ”¹è‰¯

```python
def iterative_prompt_refinement(base_prompt, pipe, iterations=3):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ®µéšçš„ã«æ”¹è‰¯ã—ã¦æœ€é©åŒ–"""
    
    # åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰é–‹å§‹
    current_prompt = base_prompt
    results = []
    
    refinements = [
        # 1å›ç›®ï¼šåŸºæœ¬çš„ãªå“è³ªå‘ä¸Š
        ", high quality, detailed, professional",
        # 2å›ç›®ï¼šã‚¹ã‚¿ã‚¤ãƒ«è¿½åŠ 
        ", digital art, trending on artstation, award winning",
        # 3å›ç›®ï¼šæŠ€è¡“çš„ä»•æ§˜è¿½åŠ 
        ", ultra detailed, 8K resolution, perfect composition, dramatic lighting"
    ]
    
    for i, refinement in enumerate(refinements[:iterations]):
        refined_prompt = current_prompt + refinement
        
        print(f"Iteration {i+1}: {refined_prompt[:100]}...")
        
        images = pipe(
            prompt=refined_prompt,
            num_inference_steps=25,
            guidance_scale=7.5,
            num_images_per_prompt=2
        ).images
        
        results.append({
            'iteration': i+1,
            'prompt': refined_prompt,
            'images': images
        })
        
        current_prompt = refined_prompt
    
    return results

# ä½¿ç”¨ä¾‹
base = "A cozy coffee shop interior with warm lighting"
refinement_results = iterative_prompt_refinement(base, pipe)
```

### ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ´»ç”¨

```python
# ç”¨é€”åˆ¥ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†
negative_prompts = {
    "youtube_thumbnail": """
        blurry, low quality, boring, plain, amateur, watermark, text overlay,
        dark, gloomy, sad, depressing, low energy, static, old fashioned
    """,
    
    "blog_image": """
        cluttered, messy, chaotic, unprofessional, low quality, distorted,
        harsh lighting, oversaturated, cartoonish, childish
    """,
    
    "icon_logo": """
        complex background, photorealistic, detailed texture, shadows,
        multiple colors, busy design, text, letters, numbers
    """,
    
    "general": """
        blurry, low quality, distorted, deformed, ugly, bad anatomy,
        watermark, signature, low resolution, pixelated
    """
}

def generate_with_negative(prompt, category, pipe):
    """ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä»˜ãã§ç”Ÿæˆ"""
    return pipe(
        prompt=prompt,
        negative_prompt=negative_prompts.get(category, negative_prompts["general"]),
        num_inference_steps=30,
        guidance_scale=8.0
    ).images[0]
```

## ğŸ“Š å“è³ªç®¡ç†ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–

### ç”Ÿæˆå“è³ªã®è©•ä¾¡

```python
def evaluate_image_quality(images, criteria):
    """ç”Ÿæˆç”»åƒã®å“è³ªè©•ä¾¡ï¼ˆä¸»è¦³çš„åŸºæº–ï¼‰"""
    
    evaluation = {
        'composition': [],    # æ§‹å›³ã®è‰¯ã•
        'clarity': [],       # é®®æ˜ã•
        'relevance': [],     # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã®é–¢é€£æ€§
        'appeal': []         # è¦–è¦šçš„é­…åŠ›
    }
    
    for i, image in enumerate(images):
        print(f"Image {i+1} evaluation:")
        print("Rate each aspect (1-5):")
        
        for criterion in criteria:
            while True:
                try:
                    score = int(input(f"{criterion}: "))
                    if 1 <= score <= 5:
                        evaluation[criterion].append(score)
                        break
                except ValueError:
                    print("Please enter a number between 1-5")
    
    # å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
    averages = {k: sum(v)/len(v) for k, v in evaluation.items()}
    return evaluation, averages

# è‡ªå‹•å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæŠ€è¡“çš„æŒ‡æ¨™ï¼‰
def technical_quality_check(image):
    """æŠ€è¡“çš„å“è³ªæŒ‡æ¨™ã®ç¢ºèª"""
    import numpy as np
    from PIL import ImageStat
    
    # åŸºæœ¬çµ±è¨ˆ
    stat = ImageStat.Stat(image)
    
    metrics = {
        'mean_brightness': np.mean(stat.mean),
        'contrast': np.std(stat.mean),
        'size': image.size,
        'mode': image.mode
    }
    
    return metrics
```

### æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç™ºè¦‹

```python
def parameter_optimization(prompt, pipe, param_ranges):
    """ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆã—ã¦æœ€é©åŒ–"""
    
    import itertools
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ç”Ÿæˆ
    param_combinations = list(itertools.product(*param_ranges.values()))
    param_names = list(param_ranges.keys())
    
    results = []
    
    for i, combination in enumerate(param_combinations):
        config = dict(zip(param_names, combination))
        config['prompt'] = prompt
        
        print(f"Testing combination {i+1}/{len(param_combinations)}: {config}")
        
        try:
            image = pipe(**config).images[0]
            
            # æŠ€è¡“çš„å“è³ªè©•ä¾¡
            quality = technical_quality_check(image)
            
            results.append({
                'config': config,
                'image': image,
                'quality': quality,
                'score': quality['contrast']  # ä»®ã®è©•ä¾¡æŒ‡æ¨™
            })
            
        except Exception as e:
            print(f"Error with config {config}: {e}")
    
    # æœ€é«˜ã‚¹ã‚³ã‚¢ã®è¨­å®šã‚’è¿”ã™
    best_result = max(results, key=lambda x: x['score'])
    return best_result, results

# ä½¿ç”¨ä¾‹ï¼šYouTubeã‚µãƒ ãƒã‚¤ãƒ«æœ€é©åŒ–
optimization_ranges = {
    'num_inference_steps': [20, 25, 30],
    'guidance_scale': [7.0, 7.5, 8.0, 8.5],
    'height': [576],
    'width': [1024]
}

best_config, all_results = parameter_optimization(
    "Exciting gaming setup with RGB lighting",
    pipe,
    optimization_ranges
)
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### ã‚ˆãã‚ã‚‹å•é¡Œã®å¯¾å‡¦ãƒ•ãƒ­ãƒ¼

```python
def troubleshoot_generation(pipe, prompt, config):
    """ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã®æ®µéšçš„ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    
    troubleshooting_steps = [
        {
            'name': 'Memory cleanup',
            'action': lambda: (torch.cuda.empty_cache(), gc.collect()),
            'description': 'GPUãƒ»RAMãƒ¡ãƒ¢ãƒªã®ã‚¯ãƒªã‚¢'
        },
        {
            'name': 'Reduce resolution',
            'action': lambda: config.update({'height': 768, 'width': 768}),
            'description': 'è§£åƒåº¦ã‚’ä¸‹ã’ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›'
        },
        {
            'name': 'Reduce batch size',
            'action': lambda: config.update({'num_images_per_prompt': 1}),
            'description': 'ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’1ã«å‰Šæ¸›'
        },
        {
            'name': 'Reduce inference steps',
            'action': lambda: config.update({'num_inference_steps': 15}),
            'description': 'æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å‰Šæ¸›'
        },
        {
            'name': 'Enable sequential offload',
            'action': lambda: pipe.enable_sequential_cpu_offload(),
            'description': 'ã‚ˆã‚Šç©æ¥µçš„ãªCPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰'
        }
    ]
    
    for step in troubleshooting_steps:
        print(f"Trying: {step['name']} - {step['description']}")
        
        try:
            step['action']()
            
            # ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            test_image = pipe(
                prompt=prompt,
                **{k: v for k, v in config.items() if k != 'prompt'}
            ).images[0]
            
            print(f"âœ… Success with {step['name']}")
            return test_image, config
            
        except Exception as e:
            print(f"âŒ {step['name']} failed: {e}")
            continue
    
    print("ğŸ’¥ All troubleshooting steps failed")
    return None, config
```

## ğŸ“ˆ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æã¨æ”¹å–„

### ç”ŸæˆåŠ¹ç‡ã®è¿½è·¡

```python
import time
import json
from datetime import datetime

class WorkflowTracker:
    def __init__(self):
        self.sessions = []
        self.current_session = None
    
    def start_session(self, session_name):
        """æ–°ã—ã„ä½œæ¥­ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
        self.current_session = {
            'name': session_name,
            'start_time': datetime.now(),
            'generations': [],
            'total_time': 0,
            'success_rate': 0
        }
    
    def log_generation(self, prompt, config, success, generation_time):
        """å€‹åˆ¥ã®ç”Ÿæˆã‚’è¨˜éŒ²"""
        if self.current_session:
            self.current_session['generations'].append({
                'prompt': prompt[:50] + '...',
                'config': config,
                'success': success,
                'time': generation_time,
                'timestamp': datetime.now().isoformat()
            })
    
    def end_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¦çµ±è¨ˆã‚’è¨ˆç®—"""
        if self.current_session:
            generations = self.current_session['generations']
            
            self.current_session['total_time'] = sum(g['time'] for g in generations)
            self.current_session['success_rate'] = sum(g['success'] for g in generations) / len(generations) if generations else 0
            self.current_session['end_time'] = datetime.now()
            
            self.sessions.append(self.current_session)
            self.current_session = None
    
    def get_statistics(self):
        """å…¨ä½“çš„ãªçµ±è¨ˆã‚’å–å¾—"""
        if not self.sessions:
            return "No sessions recorded"
        
        total_generations = sum(len(s['generations']) for s in self.sessions)
        avg_success_rate = sum(s['success_rate'] for s in self.sessions) / len(self.sessions)
        avg_time_per_image = sum(s['total_time'] for s in self.sessions) / total_generations if total_generations > 0 else 0
        
        return {
            'total_sessions': len(self.sessions),
            'total_generations': total_generations,
            'average_success_rate': avg_success_rate,
            'average_time_per_image': avg_time_per_image
        }

# ä½¿ç”¨ä¾‹
tracker = WorkflowTracker()
tracker.start_session("YouTube thumbnails batch")

# ç”Ÿæˆå‡¦ç†ã®ä¾‹
start_time = time.time()
try:
    image = pipe(prompt="Gaming setup", height=576, width=1024).images[0]
    success = True
except:
    success = False
generation_time = time.time() - start_time

tracker.log_generation("Gaming setup", {"height": 576, "width": 1024}, success, generation_time)
tracker.end_session()

print(tracker.get_statistics())
```

ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰ã‚’å‚è€ƒã«ã€åŠ¹ç‡çš„ãªSDXLç”»åƒç”Ÿæˆã‚’å®Ÿè·µã—ã¦ãã ã•ã„ã€‚æ¬¡ã¯[SDXL ä½¿ç”¨ä¾‹](sdxl-examples.md)ã§å…·ä½“çš„ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ç¢ºèªã§ãã¾ã™ã€‚